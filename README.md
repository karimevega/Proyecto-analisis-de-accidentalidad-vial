# AnÃ¡lisis de Accidentalidad Vial en Barranquilla con Big Data

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de anÃ¡lisis de datos de accidentalidad vial en Barranquilla, Colombia, utilizando tecnologÃ­as de Big Data para procesamiento tanto en batch como en tiempo real. El objetivo es identificar patrones de riesgo, zonas peligrosas y tendencias que puedan apoyar la toma de decisiones en seguridad vial.

## ğŸ¯ ProblemÃ¡tica

En las principales ciudades del paÃ­s, los accidentes de trÃ¡nsito son una de las causas mÃ¡s frecuentes de emergencias urbanas. Aunque existen reportes y bases de datos, muchas veces no se analizan en tiempo real, lo que impide detectar zonas peligrosas o patrones de riesgo que podrÃ­an prevenir futuros accidentes.

*Pregunta de investigaciÃ³n:* Â¿CÃ³mo analizar grandes volÃºmenes de datos sobre accidentes de trÃ¡nsito para identificar patrones de riesgo y apoyar la toma de decisiones en seguridad vial?

## ğŸ“Š Dataset

- *Nombre:* Accidentalidad en Barranquilla
- *Fuente:* [Datos Abiertos de Colombia](https://www.datos.gov.co/)
- *URL:* https://www.datos.gov.co/api/views/yb9r-2dsi/rows.csv

### Columnas principales:
- Fecha y hora del accidente
- Gravedad del accidente
- Clase de accidente (Atropello, Choque, Volcamiento, etc.)
- Sitio exacto del accidente
- Cantidad de heridos y muertos
- AÃ±o, mes y dÃ­a del accidente

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- *Apache Hadoop 3.x:* Sistema de archivos distribuido (HDFS)
- *Apache Spark 3.5.3:* Procesamiento de datos en batch
- *Apache Kafka 3.6.2:* Sistema de mensajerÃ­a distribuida
- *Spark Streaming:* Procesamiento de datos en tiempo real
- *PySpark:* API de Python para Spark
- *Python 3.x:* Lenguaje de programaciÃ³n
- *ZooKeeper:* CoordinaciÃ³n de servicios distribuidos

## ğŸ—ï¸ Arquitectura de la solucion en spark 


### Procesamiento en Batch
1. Carga del dataset desde HDFS
2. AnÃ¡lisis exploratorio de datos (EDA)
3. IdentificaciÃ³n de patrones y tendencias
4. Almacenamiento de resultados procesados

### Procesamiento en Tiempo Real
1. SimulaciÃ³n de reportes de accidentes con Kafka Producer
2. Consumo de datos con Spark Streaming
3. AnÃ¡lisis en ventanas de tiempo (1 minuto)
4. VisualizaciÃ³n de estadÃ­sticas en tiempo real

## ğŸ“ Estructura del Proyecto

â”œâ”€â”€ analisis_accidentalidad.py          # Script de procesamiento en batch
â”œâ”€â”€ kafka_producer_accidentes.py        # Productor de Kafka (datos simulados)
â”œâ”€â”€ spark_streaming_consumer_accidentes.py  # Consumidor Spark Streaming
â””â”€â”€ README.md                           # Este archivo

### InstalaciÃ³n de dependencias:
bash
sudo pip install pyspark
pip install kafka-python


## ğŸš€ CÃ³mo Ejecutar el Proyecto

### Paso 1: Preparar el entorno

#### 1.1 Iniciar Hadoop
bash
# Conectarse como usuario hadoop
su - hadoop
# Password: hadoop

# Iniciar el clÃºster de Hadoop
start-all.sh


#### 1.2 Crear directorio en HDFS y cargar dataset
bash
# Crear carpeta en HDFS
hdfs dfs -mkdir /AccidentalidadVial

# Descargar el dataset
wget -O accidentalidad_barranquilla.csv https://www.datos.gov.co/api/views/yb9r-2dsi/rows.csv

# Copiar al HDFS
hdfs dfs -put accidentalidad_barranquilla.csv /AccidentalidadVial

# Verificar
hdfs dfs -ls /AccidentalidadVial


### Paso 2: Procesamiento en Batch
bash
# Cambiar a usuario vboxuser
# Password: bigdata

# Ejecutar anÃ¡lisis en batch
python3 analisis_accidentalidad.py


*Resultados del anÃ¡lisis batch:*
- Esquema del dataset
- EstadÃ­sticas bÃ¡sicas
- DistribuciÃ³n por gravedad y clase de accidente
- Accidentes por aÃ±o, mes y dÃ­a de la semana
- Top 10 sitios con mÃ¡s accidentes
- Accidentes con heridos y muertos
- Total de vÃ­ctimas

### Paso 3: Procesamiento en Tiempo Real

#### 3.1 Iniciar ZooKeeper y Kafka

*Terminal 1 - ZooKeeper:*
bash
sudo /opt/Kafka/bin/zookeeper-server-start.sh /opt/Kafka/config/zookeeper.properties


*Terminal 2 - Kafka:*
bash
sudo /opt/Kafka/bin/kafka-server-start.sh /opt/Kafka/config/server.properties


#### 3.2 Crear topic de Kafka
*Terminal 3:*
bash
/opt/Kafka/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic accidentes_tiempo_real

# Verificar
/opt/Kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092


#### 3.3 Ejecutar Productor
*Terminal 4:*
bash
python3 kafka_producer_accidentes.py


#### 3.4 Ejecutar Consumidor con Spark Streaming
*Terminal 5:*
bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3 spark_streaming_consumer_accidentes.py


### Paso 4: Monitorear la ejecuciÃ³n
#### Interfaces Web:
- *Spark Jobs (context web UI):* http://192.168.1.20:4040

## ğŸ” AnÃ¡lisis Realizados

1. *AnÃ¡lisis de gravedad:* ClasificaciÃ³n de accidentes por nivel de severidad
2. *AnÃ¡lisis de tipos:* DistribuciÃ³n por clase de accidente (atropello, choque, etc.)
3. *AnÃ¡lisis temporal:* IdentificaciÃ³n de perÃ­odos de mayor riesgo
4. *AnÃ¡lisis geogrÃ¡fico:* DetecciÃ³n de puntos crÃ­ticos (zonas peligrosas)
5. *AnÃ¡lisis de vÃ­ctimas:* CuantificaciÃ³n de impacto humano
6. *AnÃ¡lisis en tiempo real:* Procesamiento de eventos conforme ocurren

## ğŸ“ Conceptos Implementados

### RDDs y DataFrames de Spark
- Uso de DataFrames para anÃ¡lisis estructurado
- Transformaciones: filter, select, groupBy, agg
- Acciones: show, count, collect

## ğŸ‘¨â€ğŸ’» Autor

-**Karime Vega**
- Universidad:Universidad Nacional Abierta y a Distancia
- Curso: Big Data

## ğŸ“š Referencias

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Datos Abiertos Colombia](https://www.datos.gov.co/)
- [PySpark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
